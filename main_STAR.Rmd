---
title: "Experimento STAR"
author: "Javier Herrero Pérez"
date: "2026-02-02"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

El Proyecto STAR fue un experimento aleatorio controlado (RCT) diseñado para responder una pregunta fundamental de política pública: ¿Realmente importa el tamaño de la clase para el aprendizaje? En un contexto observacional, esta pregunta es difícil de responder porque las clases pequeñas suelen estar en distritos ricos o con padres muy implicados (confundidores). Para evitar esto, el proyecto STAR asignó aleatoriamente a más de 7,000 estudiantes y sus profesores a tres tipos de grupos: clases pequeñas (13-17 alumnos), clases regulares (22-25 alumnos) y clases regulares con un asistente.

El objetivo de esta actividad es demostrar que, mientras los datos se mantengan bajo el diseño experimental (aleatorios), la diferencia de medias nos da el Efecto Causal. Sin embargo, en cuanto introducimos un criterio de selección (como favorecer a los alumnos con peores notas), rompemos la aleatoriedad y entramos en el terreno de los datos observacionales, donde las conclusiones pueden ser totalmente erróneas si no se corrigen adecuadamente.


# Los datos

```{r cars}
library(dplyr)
library(AER)
data(STAR)

```


```{r}
# Convertir a formato long
nam <- c("star", "read", "math", "lunch", "school", "degree", "ladder",
         "experience", "tethnicity", "system", "schoolid")
lev <- c("k", "1", "2", "3")

star <- reshape(STAR, idvar = "id", ids = row.names(STAR),
                times = lev, timevar = "grade", direction = "long",
                varying = lapply(nam, function(x) paste(x, lev, sep = "")))

# Mejorar nombres y tipos
names(star)[5:15] <- nam
star$id <- factor(star$id)
star$grade <- factor(star$grade, levels = lev,
                     labels = c("kindergarten", "1  st", "2nd", "3rd"))
```

# Estimación insesgada del efecto causal medio

La nota para lectura:

```{r}
# Obtenemos el efecto causal para los estudiantes de grade=3rd

library(broom)
lectura <- lm(read ~ star, data = star %>% filter(grade=='3rd')) 

tidy(lectura) 
confint(lectura,2) 
```

La nota para matemáticas: 

```{r}
matematicas <- lm(math ~ star, data = star %>% filter(grade=='3rd')) 
tidy(matematicas) 
confint(matematicas,2) 
```
**Preguntas**

- **Hemos calculado la diferencia de medias en las puntuaciones de lectura entre alumnos en clases pequeñas y regulares. ¿Por qué podemos interpretar esta diferencia como el efecto causal medio del tamaño de clase sobre el rendimiento académico?¿Cuál es la diferencia promedio entre clases pequeñas y normales?**

Porque gracias a la aleatorización, el grupo de "clases pequeñas" y "regulares" son estadísticamente idénticos en todo (potencial académico, nivel socioeconómico, etc.) antes de empezar el estudio. La única diferencia sistemática entre ellos es el tamaño de la clase. Por tanto, cualquier diferencia posterior en las notas ($Y$) debe haber sido causada por el tratamiento ($D$).

Comparando la variable `starsmall`, para lectura la clase pequeña saca 8.53 más que en la clase grande, mientras que en matemáticas es 6.87 


- **Es posible añadir covariables (como género o etnicidad) en la regresión. Reformula la estimación incluyendo covariables en la expresión (busca en la ayuda de la librería AER). ¿Por qué incluir covariables no cambia la validez causal del estimador, pero puede hacerlo más eficiente (reducir su varianza)? Prueba la estimación del efecto para los distintos grados (kindergarten, 1st, 2nd, 3rd)**


En un experimento ideal, las covariables están equilibradas. Añadirlas no cambia el valor esperado del coeficiente porque no están correlacionadas con el tratamiento ya que la asignación fue al azar.


Al incluir variables que explican parte de la varianza de las notas (como el género), el "ruido" del modelo disminuye (baja el $R^2$ no explicado). Esto reduce el error estándar del estimador, haciendo que tus intervalos de confianza sean más estrechos.

# Introducción de sesgo de selección

## Creación de la variable `rendimiento previo`

Vamos a modificar los datos para convertirlos en observacionales. Para ello vamos a simular un tipo de mecanismo de asignación al tratamiento que podría existir en el mundo real.

**Mecanismo no aleatorio de asignación del tratamiento**: aplicamos el tratamiento (grupos reducidos) a los estudiantes cuyo rendimiento haya estado en el curso anterior por debajo del tercer decil (30%) de la distribución de notas.

Para ello vamos a crear la variable rendimiento previo: queremos medir el rendimiento antes del tratamiento en cada grado.

```{r}
library(dplyr)

star <- star %>%
  arrange(id, grade) %>%
  group_by(id) %>%
  mutate(
    read_lag = lag(read),
    math_lag = lag(math)
  ) %>%
  ungroup()
```


**Preguntas**

- **¿Para qué grado read_lag es siempre NA?**

Para Kindergarten. 

- **¿Por qué tiene sentido desde el punto de vista temporal?**

Es el primer año de escolarización registrado en el estudio; no existen datos de un "año anterior" dentro del experimento.

## Definimos alumnos con bajo rendimiento previo

Definimos como bajo rendimiento estar por debajo del tercer decil (30%) en la nota de lectura o matemáticas del grado anterior.

```{r}
star <- star %>%
  group_by(grade) %>%
  mutate(
    q30_read = quantile(read_lag, 0.3, na.rm = TRUE),
    q30_math = quantile(math_lag, 0.3, na.rm = TRUE),
    bottom30 = (read_lag <= q30_read) | (math_lag <= q30_math)
  ) %>%
  ungroup()
```

**Pregunta**

- **¿Por qué calculamos los cuantiles por grado y no globalmente?**

Porque la distribución de notas cambia con la edad. El 30% inferior de un niño de 5 años no es el mismo nivel de competencia que el 30% de uno de 9 años. Hacerlo por grado asegura que estamos seleccionando a los "rezagados" respecto a sus pares actuales.


## Filtrado de los datos

Conservamos solo a los alumnos tratados (small) que están por debajo del 30% de la distribución. El resto de alumnos no tratados se mantienen todos.

```{r}
star_sel <- star %>%
  filter(
    !(star == "small" & !bottom30)
  )
```

Observa que no se redefine el tratamiento; tan solo se condiciona la muestra.

**Pregunta**

- **¿Qué impacto tiene este filtro sobre el conjunto de tratados y no tratados?**


Se está creando un escenario donde solo los alumnos con dificultades acceden al tratamiento (clase pequeña). Los alumnos "buenos" solo están en el grupo control. En el grupo small, desaparecerán todos los que superen el percentil 30 (un 70% aproximadamente). En el grupo control no se elimina a nadie.

## ¿A quién estamos eliminando?

```{r}

star %>%
  mutate(retained = !(star == "small" & !bottom30)) %>%
  group_by(star) %>%
  summarise(prop_retained = mean(retained, na.rm=TRUE))
```

**Pregunta**

- **¿Qué proporción de alumnos tratados desaparece?**



- **¿Se elimina algún alumno del grupo control (no tratados)?**



## Efectos de la intervención en la muestra seleccionada

A continuación comparamos el rendimiento previo entre tratados y no tratados en la muestra filtrada. Para lectura:


```{r}
lectura <- lm(read ~ star, data = star_sel |> filter(grade=='3rd'))
lectura |> tidy() 
lectura |> confint(2) 
```

Para matemáticas:

```{r}
matematicas <- lm(math ~ star, data = star_sel |> filter(grade=='3rd')) 
matematicas |> tidy() 
matematicas |> confint(2) 
```

**Preguntas**

- **¿Significa la estimación que el efecto no es beneficioso para el grupo considerado?**

No, el efecto sigue siendo positivo, pero la estimación ahora está "contaminada". Al comparar "alumnos con dificultades en clases pequeñas" contra "todos los alumnos (incluidos los brillantes) en clases normales", es muy probable que el coeficiente de star salga negativo o muy bajo. El sesgo de selección está ocultando el beneficio real.


- **¿Son comparables los grupos antes del tratamiento?**

No. Se ha roto la propiedad de ignorabilidad. Ahora el grupo de tratamiento es intrínsecamente "peor" académicamente que el grupo control antes de empezar el análisis.

## Intento de corrección con controles

Añadimos controles por rendimiento previo, perfil socioeconómico y características del profesor:


```{r}
lectura <- lm(read ~ star + read_lag + math_lag + lunch + gender + ethnicity + degree + experience + tethnicity, 
              data = star_sel |> filter(grade=='3rd'))
lectura |> tidy()
lectura |> confint(2) 
```

**Preguntas**

- ¿Se corrige el sesgo?


# Discusión final

**Pregunta**

- **¿Cuál es el origen fundamental del sesgo en esta actividad?**

  - Mala especificación del modelo

  - Variables omitidas
  
  - **Problema de selección muestral**: Se ha forzado una correlación entre el tratamiento y la capacidad del alumno.
  
  - Falta de tamaño muestral
  
- **En el experimento STAR original, la asignación al tratamiento es aleatoria. Sin embargo, tras aplicar el filtro de la actividad, los datos resultantes se comportan como observacionales. Explica por qué, indicando qué propiedad clave de los datos experimentales se ha perdido.**


Se ha perdido la Independencia (o Aleatoriedad). En los datos originales, tras el filtro, el tratamiento $D$ depende de $Y(t-1)$, que está altamente correlacionado con los resultados potenciales. Los datos ahora son observacionales porque el "mecanismo de asignación" ya no es una moneda al aire, sino una regla basada en el rendimiento.

# Extensiones
Repetir el análisis por grado e incluyendo covariables

```{r}
# Extensiones: Recuperando el efecto causal

library(purrr)

# Función para ejecutar modelos y extraer el coeficiente de 'small'
estudiar_grado <- function(g) {
  df_sub <- star_sel %>% filter(grade == g)
  
  # Modelo 1: Sesgado (sin controles, solo el filtro aplicado)
  m1 <- lm(read ~ star, data = df_sub)
  
  # Modelo 2: Corregido (añadimos la variable que causó el sesgo: rendimiento previo)
  # También añadimos controles socioeconómicos para ganar precisión
  m2 <- lm(read ~ star + read_lag + math_lag + lunch + experience, data = df_sub)
  
  # Extraemos resultados
  bind_rows(
    tidy(m1) %>% filter(term == "starsmall") %>% mutate(modelo = "Sesgado", grado = g),
    tidy(m2) %>% filter(term == "starsmall") %>% mutate(modelo = "Corregido", grado = g)
  )
}

# Aplicamos a los grados donde tenemos lag (1st, 2nd, 3rd)
grados_analisis <- c("1  st", "2nd", "3rd")
resultados_ext <- map_df(grados_analisis, estudiar_grado)

# Visualizamos los resultados
print(resultados_ext)
```



Elabora una estrategia para recuperar el efecto causal en la muestra de datos observacionales
Discutir paralelismos con missing not at random